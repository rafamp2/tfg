DEV_MODE: user ##user or dev, cambia la autorizacion sobre cosas que se pueden hacer
DEVICE: cuda

MODELS_DIR: ./tfg_marta/models

EMBEDDINGS_PATH: all-MiniLM-L6-v2

VECTORDB_TYPE: chroma
VECTORDB_PATH: vectordb/chroma

TTS_PATH: src/tmp

# Los wrappers son: TRANSFORMERS, LLAMACPP y CTRANSFORMERS
WRAPPER: TRANSFORMERS

#mistral7b q5: mistral-7b-instruct-v0.2.Q5_K_M.gguf
#mistral7b q6: mistral-7b-instruct-v0.2.Q6_K.gguf
#mistral7b q8: mistral-7b-instruct-v0.2.Q8_0.gguf
#llama7b q5: llama-7b.Q5_K_M.gguf
#llama7b q6: llama-7b.Q6_K.gguf
#google gemma 2b GPTQ: gemma-1.1-2b-it-GPTQ
LLM_PATH: gemma-1.1-2b-it-GPTQ

# Puede ser: llama, mistral, zephyr o gemma
PROMPT_TYPE: gemma

LLM_CONFIG:
  MAX_NEW_TOKENS: 512
  TEMPERATURE: 0.2
  REPETITION_PENALTY: 1.1
  CONTEXT_LENGTH: 4096
  N_CTX: 2048
  N_GPU_LAYERS: 12

BASE_RETRIEVER_CONFIG:
  SEARCH_K: 4

RERANKER_PATH: bge-reranker-base
RERANKER_TYPE: bge

RERANK_RETRIEVER_CONFIG:
  SEARCH_K: 10
  TOP_N: 4

COMPRESSION_RETRIEVER_CONFIG:
  SEARCH_K: 10
  SIMILARITY_THRESHOLD: 0.5

TTS_PATH: XTTS-v2
TTS_CONFIG: XTTS-v2/config.json
AUDIO_CONFIG:
  AUDIO_DIR: ./audio
  VOICE_FILE: voice_style.wav
  

TEXT_SPLIT_MODE: default  
CHUNK_SIZE: 500
CHUNK_OVERLAP: 50
SEPARATORS: ["\n\n", "\n", ". ", " ", ""]

